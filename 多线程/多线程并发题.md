
# 多线程&并发

## 1、Java中实现多线程有几种方法

- 继承Thread类

- Runnable接口

- 实现Callable接口通过FutureTask（Runnable的实现类）包装器来创建Thread线程；

使用ExecutorService、Callable、Future实现有返回结果的多线程（也就是使用了ExecutorService来管理前面的三种方式）。 



#### 实现Runnable接口和Callable接口的区别

Callable（简单）与Runnable的区别：

1. 可以有返回值 
2. 可以抛出异常
3. 方法不同，run()/call()

所以用Callable要好

```java
class MyThread implements Callable<String> {

    // 返回值与泛型相同
    @Override
    public String call() throws Exception {
        return "123";
    }
}

main { 
    MyThread my = new MyThread();
    // 实现Callable接口通过FutureTask（Runnable的实现类）包装器来创建Thread线程
    FutureTask<String> task = new FutureTask<>(myThread);
     // 结果会被缓存，效率高
    new Thread(task,"A").start();
    // 这个Get 方法可能会产生阻塞，把他方法最后
    String s = task.get();
}
```

Callable 不认识Thread 则通过Runnable

细节：
1、有缓存
2、结果可能需要等待，会阻塞！ 



## 2、如何停止一个正在运行的线程 

如何关闭一个线程？不要关闭线程，关闭线程的概念已经被否定了。所以就直接让它正常运行完就行。

但是目前有停止一个阻塞的线程。依旧是可以使用interrupt方法

1. 使用退出标志 flag ，使线程正常退出，也就是需要达到退出的条件的时候设置为 false即可。
2. 使用stop方法强行终止，但是**不推荐**这个方法，因为stop和suspend及resume一样都是过期作废的 方法。
3. 使用interrupt方法中断线程，使用会抛出异常。暂没见过用来控制业务逻辑的



## 3、notify()和notifyAll()有什么区别？

- notify可能会导致死锁，而notifyAll则不会 
- 任何时候只有一个线程可以获得锁，也就是说只有一个线程可以运行synchronized 中的代码 
- 使用notifyall,可以唤醒 所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。
- notify() 是对notifyAll()的一个优化，但它有很精确的应用场景，并且要求正确使用。不然可能导致死锁。
- wait() 应配合while循环使用，不应使用if，务必在wait()调用前后都检查条件，如果不满足，必须调用 notify()唤醒另外的线程来处理，自己继续wait()直至条件满足再往下执行。



## 4、sleep()和wait() 有什么区别？

**1、来自不同的类** 

wait  => Object
sleep => Thread 

在公司中一般都不用，用TimeUtil，在JUC包中

**2、关于锁的释放** 

`sleep()`方法导致了程序暂停执行指定的时间，让出cpu该其他线程，但是他的监控状态依然保持者，当 指定的时间到了又会自动恢复运行状态。在调用sleep()方法的过程中，线程不会释放对象锁.

调用`wait()`方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用 notify()方法后本线程才进入对象锁定池准备，获取对象锁进入运行状态。

**3、使用的范围是不同的** 

wait： 必须在Synchronize同步代码块中

sleep：任何地方都可以

**4、是否需要捕获异常**
wait  不需要捕获异常 

sleep 必须要捕获异常 





## 5、volatile 是什么?

**保证可见性、有序性**

计算机并不会根据代码顺序按部就班地执行相关指令。

在字节码层面：只加了ACC_VOLAILE

在 VM 层面：读写都加了层屏障

```java
StoreStroeBarrier		LoadLoadBarrier
	volatile 写			  volatile 读
StoreLoadBarrier		LoadStoreBarrier
```

volatile修饰之后，那么就具备了两层语义：

1. 保证了不同线程对这个变量进行操作时的可见性，volatile关键字会强制将修改的值立即写入主存。

   将可见性的时候，就要谈JMM

2. 禁止进行指令重排序。

   工作原理：**内存屏障**，可以保证避免指令重排的现象产生！

   invokespeclie 与 astroe_1 的重排，避免位于栈顶的句柄引用
   
   invoke是调用初始化init
   
   astroe是把对内的首地址赋给引用变量 
   
   

不保证原子性

一般用于 状态标记量 和 **单例模式的双检锁**（手写）

1. 为 uniqueInstance 分配内存空间 
2. 初始化 uniqueInstance 
3. 将 uniqueInstance 指向分配的内存地址 



### 5.1、什么是JMM?

java memory model

JMM ： Java内存模型，不存在的东西，概念！约定！ 



**关于JMM的一些同步的约定：** 

1. 线程解锁前，必须把共享变量立刻刷回主存。
2. 线程加锁前，必须读取主存中的新值到工作内存中！
3. 注意：加锁和解锁是同一把锁 



线程a要到主存中拿变量，并不会仅仅直接读取，而是拷贝一份到自己线程的工作内存中，真正操作的是自己拷贝的一份。
线程解锁，立马把共享变量刷回去。不会直接操作主存

线程：工作内存，主内存









## 6、volatile与synchronized的区别

- volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。 
- volatile仅能使用在变量级别；synchronized则可以使用在变量、方法 
- volatile仅能实现变量的修改可见性，并不能保证原子性；synchronized则可以保证变量的修改可见性和原子性。
-  volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。 



## 6、Thread 类中的start() 和 run() 方法有什么区别？

start()方法被用来启动新创建的线程，而且start()内部调用了run()方法 

和直接调用run()方法的效果不一样。

当你调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动，start()方法才会启动新线程。





## 7、常用辅组类（必会）

1. CountDownLatch 计数器 Down知道是减法，算倒计时

   允许一个或多个线程等待，知道在其他线程中执行的一组操作完成同步辅助

   ```java
   package com.kuang.add;
   import java.util.concurrent.CountDownLatch;
   // 计数器 
   public class CountDownLatchDemo {    
       public static void main(String[] args) throws InterruptedException {        
           // 总数是6，必须要执行任务的时候，再使用！        
           CountDownLatch countDownLatch = new CountDownLatch(6);
           for (int i = 1; i <=6 ; i++) {            
               new Thread(()->{                							  		 					
                   System.out.println(Thread.currentThread().getName()+" Go out");       				  
                   countDownLatch.countDown(); // 数量-1            
            	}, String.valueOf(i)).start();        
           }
           
           countDownLatch.await(); // 等待计数器归零，然后再向下执行
           System.out.println("Close Door");
       } 
   }
   ```

   原理：
   `countDownLatch.countDown();` // 数量-1

   `countDownLatch.await();` // 等待计数器归零，然后再向下执行
   每次有线程调用 countDown() 数量-1，假设计数器变为0，countDownLatch.await() 就会被唤醒，继续执行

2. CyclicBarrier  加法计数器

   ```java
   CyclicBarrier cyclicBarrier = new CyclicBarrier(7, ()->{         
       System.out.println("召唤神龙成功！"); 
   });                                                     
   // 等待数字累加到7的时候才激活执行线程                                                       
   cyclicBarrier.await();                                                            
   ```
   
   
   
3. Semaphore：一个计数信号量。在概念上信号量维持一组许可证。如果有必要，每个acquire()都会阻塞，知道许可证可用，然后才能使用。

   在并发用的非常的多

   限制线程数量，限流。距离：停车位

   ```java
   public class Test {
       public static void main(String[] args) {
           // 线程数量：停车位! 限流！
           Semaphore semaphore = new Semaphore(3);
           for (int i = 1; i <=6 ; i++) {
               new Thread(() -> {
                   // acquire() 得到
                   try {
                       semaphore.acquire();
                       System.out.println(Thread.currentThread().getName()+"抢到车位");
                       TimeUnit.SECONDS.sleep(2);
                       System.out.println(Thread.currentThread().getName()+"离开车位");
                   } catch (InterruptedException e) {
                       e.printStackTrace();
                   } finally {
                       semaphore.release();
                       // release() 释放
                   }
                },String.valueOf(i)).start();
           }
       }
   }
   ```

   ```
   2抢到车位
   3抢到车位
   1抢到车位
   -----------两秒
   2离开车位
   1离开车位
   3离开车位
   4抢到车位
   5抢到车位
   6抢到车位
   -----------两秒
   4离开车位
   5离开车位
   6离开车位
   ```
   
   原理：
   `semaphore.acquire(); `获得，假设如果已经满了，则等待，等待有线程被释放
   
   `semaphore.release(); `释放，会将当前的信号量释放 + 1，然后唤醒等待的线程
   作用： 多个共享资源互斥的使用！并发限流，控制大的线程数！
   
   定义了资源总量state=permits，当state > 0 时就能获得锁，并将state 减1，当state = 0 时只能等待其他线程释放锁，当释放锁时 state 加1，其他等待线程又能获得这个锁。当permits 定义为1 时，就是互斥锁，当permits > 1 就是共享锁。





## 8、读写锁

一个用于只写操作，一个用于只读操作

独占锁（写锁） 一次只能被一个线程占有 

共享锁（读锁） 多个线程可以同时占有 

```java
ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();

readWriteLock.writeLock().lock();
readWriteLock.writeLock().unlock();

readWriteLock.readLock().lock();
readWriteLock.readLock().unlock();
```

* 读-读  可以共存
* 读-写  不能共存
* 写-写  不能共存



## 9、阻塞队列

可以叫工作队列

主要是回忆任务进入线程池后的流程图，就能知道工作队列的作用。

**四组API**

 `ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue<>(3);`

| 方式         | 抛出异常 | 返回true/false，不抛出异常 | 阻塞 等待 | 时间范围内等待，再返回值 |
| ------------ | -------- | -------------------------- | --------- | ------------------------ |
| 添加         | add      | oﬀer()                     | put()     | oﬀer( , , )              |
| 移除         | remove   | poll()                     | take()    | poll( , )                |
| 检测队首元素 | element  | peek                       | -         | -                        |

LinkedList

Propertis

Delay

SynchronousQueue 同步队列

- 进去一个元素，必须等待取出来之后，才能再往里面放一个元素！
- ` BlockingQueue<String> blockingQueue = new SynchronousQueue<>(); `// 同步队列
- 存：`blockingQueue.put("1")` 取：`blockingQueue.take()`





## 10、线程池

线程池：5大方法、7大参数、4种拒绝策略

> 线程池：5大方法

```java
// 单个线程 
ExecutorService threadPool = Executors.newSingleThreadExecutor();	
// 创建一个固定的线程池的大小 
ExecutorService threadPool = Executors.newFixedThreadPool(5); 
// 可伸缩的，依赖于操作系统能够创建的大线程大小
ExecutorService threadPool = Executors.newCachedThreadPool(); 	
// 支持定时以及周期性执行任务的需求。 
ExecutorService threadPool = Executors.newScheduledThreadPool();
// JDK8引入，创建持有足够线程的线程池支持给定的并行度，并使用多个对象减少竞争。ForkJoin 
ExecutorService threadPool = Executors.newWorkStealingPool();
 
// 关闭线程
threadPool.shutdown();
```

> 七大参数

```java
public ThreadPoolExecutor(int corePoolSize,			// 核心线程池大小 
                          int maximumPoolSize,		// 大核心线程池大小 
                          long keepAliveTime,		// 超时了没有人调用就会释放 
                          TimeUnit unit,			// 超时单位 
                          BlockingQueue<Runnable> workQueue,// 阻塞队列 
                          ThreadFactory threadFactory,// 线程工厂：创建线程的，一般不用动 
                          RejectedExecutionHandler handler) {// 拒绝策略
    if (corePoolSize < 0 ||
        maximumPoolSize <= 0 ||
        maximumPoolSize < corePoolSize ||
        keepAliveTime < 0)
        throw new IllegalArgumentException();
    if (workQueue == null || threadFactory == null || handler == null)
        throw new NullPointerException();
    this.acc = System.getSecurityManager() == null ?
        null :
    AccessController.getContext();
    this.corePoolSize = corePoolSize;
    this.maximumPoolSize = maximumPoolSize;
    this.workQueue = workQueue;
    this.keepAliveTime = unit.toNanos(keepAliveTime);
    this.threadFactory = threadFactory;
    this.handler = handler;
}
```



> 四大拒绝策略

```java
new ThreadPoolExecutor.AbortPolicy() 		// 满了不处理并抛出异常 
new ThreadPoolExecutor.CallerRunsPolicy() 	// 哪来的回哪去！ 
new ThreadPoolExecutor.DiscardPolicy() 		// 队列满了，丢掉任务，不会抛出异常！ 
new ThreadPoolExecutor.DiscardOldestPolicy() //队列满了，尝试去和早的竞争，也不会抛出异常！ 
```





### 10.1、简述一下你对线程池的理解

（如果问到了这样的问题，可以展开的说一下线程池如何用、线程池的好处、线程池的启动策略）

- 合理利用线程池能够带来三个好处：

  1. 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
  2. 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。
  3. 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系 统的稳定性，使用线程池可以进行统一的分配，调优和监控。

  







## 11、为什么wait, notify 和 notifyAll这些方法不在thread类里面？ 

- 明显的原因是**JAVA提供的锁是对象级的而不是线程级的**，每个对象都有锁，通过线程获得。
- 线程需要等待 某些锁 那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不清除了
- 简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中，因为锁属于对象。 





## 12、为什么wait和notify方法要在同步块中调用？ 

1. 只有在调用线程拥有某个对象的独占锁时，才能够调用该对象的wait(),notify()和notifyAll()方法。
2. 如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。
3. 还有一个原因是为了避免wait和notify之间产生竞态条件。

问题8，没写完，没看懂



## 13、Java中interrupted 和 isInterrupted方法的区别？ 

interrupted() 和 isInterrupted()的主要区别是前者会将中断状态清除而后者不会。

Java多线程的中断机制是用内部标识来实现的，调用Thread.interrupt()来中断一个线程就会设置中断标识为true。

当中断线程调用静态方法Thread.interrupted()来检查中断状态时，**中断状态会被清零**。

而非静态方法 isInterrupted()用来查询其它线程的中断状态，且**不会改变中断状态**标识。





## 14、说一说自己对于 synchronized 关键字的了解 

synchronized关键字解决的是多个线程之间访问资源的同步性，它可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。 

在 Java 早期1.2版本中，synchronized属于重量级锁，效率低，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统OS帮忙完成。而操作系统实现线程之间的切换时需要从**用户态转换到内核状态**，这个状态之间的转换需要较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。

在 JDK6 后不断优化是的 synchronized 提供三种锁的实现，包括偏向锁、轻量级锁、重量级锁，还提供自动的升级和降级机制、自动取消无用锁资源。

**偏向锁**，并不是锁，是一种优化，标签。--永远偏向第一个加锁的对象。

- 因为像Vactor、StringBuffer、HashTable大多情况下只有单条线程来访问，所以 出现锁竞争的情况很少，那么就干脆的设置个偏向锁，省去竞争。所以是一种优化。

当前线程是第一个执行sync同步方法时候，对方法贴上自己的标签也就是把自己的线程id写到对象头上markword，那么下次以来便可在直接使用，省的再申请锁，这样少了很多锁竞争的过程。一旦有其他的线程过来，那么在外阻塞的线程会把标记抹掉。此时，会升级到轻量级锁--自旋锁。如果说有线程在方法内停留了很久，而在外的线程一直自旋，然而while是很消耗的资源的，所以在

1.6之前两种方式升级重量级：

- 自旋超过10次，可通过JVM调优参数修改 `-XX:PreBlockSpin`
- 等待的线程超过CUP核的二分之一。例：CPU32核，等待已经16个。现在又来了一个，那么升级。

1.6之后增加了一个：自适应自旋 Adapative Self Spinning

- 自旋就不用再自己设置，由JVM自己决定。



**偏向锁的延迟打开理论**，4秒后打开，没打开上自旋锁，打开上偏向。

- 因为在JVM启动时分配内存的时候默认会有11个线程在争夺，那么这是上偏向锁就是浪费资源。所以等4秒，让线程都完成工作后在打开偏向锁。

匿名偏向，虽然已经是偏向锁，但其实是一个匿名对象。



#### 打开偏向锁是否会提高效率？为什么？

不一定会提高，因为产生锁竞争时发生偏向锁的锁撤销，会消耗资源。

当明确有很多的线程会对同一个方法产生竞争时，就没必要打开偏向锁。



#### 轻量级锁一定比重量级锁效率高吗？

自旋时的while必然会造成资源消耗，所以在线程多且执行时间长的情况下，轻量级锁效率低，重量级则就很不错。

相反，线程少执行短，那么轻量级效率高，重量级低。



### 14.1、项目中用到了吗synchronized关键字最主要的三种使用方式

- **修饰实例方法:** 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁
- **修饰静态方法:** 访问静态 synchronized 方法占用的锁 是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁
- **修饰代码块:** 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 



## 15、Java中synchronized 和 ReentrantLock 有什么不同？ 

少了底层实现，ReentrantLock用的是AQS

相似点：都是加锁方式同步，而且都是阻塞式的同步

- 当如果一 个线程获得了对象锁，进入了同步块，其他访问该同步块的线程都必须阻塞在同步块外面等待，而进行线程阻塞和唤醒的代价是比较高的。

区别：

- Synchronized：---其中monitor是监视锁
  - 是java语言的关键字，是原生语法层面的互斥，需要jvm实现。
  - 进过编译，会在**同步代码块**的前后分别形成 monitorenter 和 monitorexit 这个两个字节码指令，然后执行两指令获取和释放monitor。
    - 如果使用 monitorenter 进入时 monitor 为 0，标识该线程可以持有 monitor 后续代码，并将monitor 加1；如果当前线程已经持有了monitor，那么monitor 继续加1；如果monitor 非0，其他线程就会进入阻塞状态。
    - 两个 monitorexit，一个是正常退出，另一个遇到异常退出。
  -  修饰方法的的情况，**同步方法**使用ACC_SYNCHRONIZED来标识，而没有monitorenter和monitorexit。JVM 通过访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。
- ReentrantLock：需要lock()和unlock()方法配合try/ﬁnally语句块来完成。
  - JUC报下提供的互斥锁，相比Synchronized，RenntrantLock类提供了一些高级功能。
  - 等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于 Synchronized来说可以避免出现死锁的情况。 
  - 公、非公平锁，多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁， ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性 能不是很好。

- Synchronized  内置的Java关键字，Lock 是一个Java类 
- Synchronized  无法判断获取锁的状态，Lock 可以判断是否获取到了锁(tryLock)
- Synchronized  会自动释放锁，lock 必须要手动释放锁！如果不释放锁，死锁
- Synchronized  线程 1（获得锁，阻塞）、线程2（等待，傻傻的等）；Lock锁就不一定会等待下去
- Synchronized  可重入锁，不可以中断的（也不是说不是说不可以，尝试获取没获取到，用户面感觉就像没生效样子），非公平；Lock 可重入锁，可以判断锁，非公平（可以自己设置）；
- Synchronized  适合锁少量的代码同步问题，Lock 适合锁大量的同步代码！ 



## 16、有三个线程T1,T2,T3,如何保证顺序执行？ 

有很多种方式可以保证，其中一种用Join。在线程3中`t2.join`，在线程2中`t1.join`





## 17、SynchronizedMap和ConcurrentHashMap有什么区别

- SynchronizedMap()和Hashtable一样，实现上在调用map所有方法时，都对整个map进行同步。

- ConcurrentHashMap的实现却更加精细，它对map中的所有桶加了锁。所以，只要有一个线程访问 map，其他线程就无法进入map，而如果一个线程在访问ConcurrentHashMap某个桶时，其他线程， 仍然可以对map执行某些操作。 

  在遍历map时，如果其他线程试图对map进行数据修 改，也不会抛出ConcurrentModiﬁcationException。





## 18、什么是线程安全

- 线程安全就是说多线程访问同一代码，不会产生不确定的结果。

- 在多线程环境中，当各线程不共享数据的时候，即都是私有（private）成员，那么一定是线程安全的。 但这种情况并不多见。

- 代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运 行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。





## 19、Thread类中的yield方法有什么作用？

- yield方法可以暂停当前正在执行的线程对象，**让其它有相同优先级的线程执行**。

- 它是一个静态方法，只保证当前线程放弃CPU占用而**不能保证使其它线程一定能占用CPU**，执行yield()的线程有可能在进入到暂停状态后马上又被执行，因为没有优先级高的线程执行。





## 20、Java线程池中submit() 和 execute()方法有什么区别？

两个方法都可以向线程池提交任务。

- `execute()`方法的返回类型是void，它定义在Executor接口中。

-  `submit()`方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了 Executor接口。

  其它线程池类像ThreadPoolExecutor和ScheduledThreadPoolExecutor都有这些方 法





## 21、如何手动创建一个线程池

开发手册建议使用 `ThreadPoolExecutor`来创建线程池，目的是让大家能更好的使用线程池。

过去的`Executors`局限性大。

配置对应的7大参数即可。











线程和进程分别是什么



## 23、Java中为什么内存不可见？（高德）

**因为Java中的线程是由CPU去调度的，而CPU中包含了L1~L3的高速缓存，当CPU调度某个线程时，会将JVM中数据拉取到CPU高速缓存中。因为CPU现在基本都是多核的，所以其他CPU内核如果也获取了相同的数据，并且有写操作的发生，就会导致多个CPU内核之间的高速缓存中的数据不一致。**

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/2746/1724058500034/0f609a74ca494f6797d2107b4c5df088.png)

## 24、什么是JMM？（天润融通）

**你了解Java的内存模型么？你要回答的是JMM。**

**如果问Java的内存结构，或者是JVM的内存结构，你再去说，堆栈方法区啥啥的……**

> JMM就是Java内存模型，因为在不同的CPU厂商下，CPU的实现机制都有一些不同，在内存和一些指令上都会存在一些差异。 所以JMM就是为了屏蔽掉硬件和操作系统带来的差异，放Java程序可以在不同的硬件和操作系统下，实现并发编程的 **原子性、可见性、禁止指令重排** 。

说白了，就是CPU内存和JVM内存之间的一个规范，这个规范可以将JVM的字节码指令转换为CPU能够识别的一些指令。

比如在×86的CPU中，原子性的保证要基于cmpxchg（Compare And Exchange）去实现，但是其他的CPU型号各自不同，**在JMM中，就会将涉及到的CAS操作根据不同的CPU情况去翻译成不同的指令**。

通过Doug Lea工作站里面的描述信息，可以看到，JMM可以帮你做到很多事情，其中重要的就是基于三大特性，对应不同的CPU做不同的实现。

https://gee.cs.oswego.edu/

如下图，除了可以看到Atomic的原子性的不同以外，还能看到内存屏障等内容。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/2746/1724058500034/e4ff45959ab443b4822bccc8a182f29b.png)

## 25、Java里面有哪些锁，他们的区别是什么？（菜鸟）

Java中的锁可以分成乐观锁的实现和悲观锁的实现。

> 乐观锁和悲观锁是俩概念，不是单独指定的某个锁。
>
> Java中针对这俩种概念做了具体的落地。
>
> 乐观锁：认为在操作的时候，没有线程和我并发操作，正常的去写，但是如果有并发会失败，返回false，成功返回true。不会阻塞、等待，失败了就再试一次……。
>
> 悲观锁：认为在操作的时候，有线程和我并发操作。就需要先去尝试竞争锁资源，如果拿不到这个资源，就将线程挂起、阻塞等待。

乐观锁：CAS，在Java中是以Unsafe类中的native方法形式存在的，到了底层，就是之前说的CPU支持的原子操作的指令，比如×86下的cmpxchg。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/2746/1724058500034/c75e0895740240f7aea1c753d0af6ceb.png)

悲观锁：synchronized，Lock锁。

## 26、乐观锁和悲观锁的区别？乐观锁一定好嘛？（菜鸟）

乐观锁不会让你的 **线程阻塞、挂起** ，可以让CPU一直调度执行竞争这个乐观锁，可以直到成功为止。

悲观锁会在竞争锁资源失败后，直接 **挂起、阻塞线程** ，等到锁资源释放后，才可能唤醒这个线程再去竞争锁资源。

核心区别就是 **是否会挂起你的线程** ，因为挂起线程这个操作，线程在用户态时不能这么做，需要从用户态转换到内核态，让OS操作系统去唤醒挂起的线程，这个用户态和内核态的切换就比较耗时。

这么看乐观锁相对悲观锁有一定的优势，但是也不是所有场景都ok。

如果竞争很激烈，导致乐观锁一直失败，那CPU就需要一直去调度他，但是又一直失败，就会有点浪费CPU的资源了。会导致CPU占用率飙高…………

在操作系统下，线程就一个阻塞状态BLOCKED，Java中为了更好的排查问题，给线程提供了三种阻塞的状态，BLOCKED，WAITING，TIMED_WAITING……

## 27、CAS到底最后加没加锁，有哪些用的地方？（猿辅导）

**CAS到底最后加没加锁：**

如果是在Java层面，他没有涉及到锁的情况，因为他不涉及线程的挂起和唤醒操作。可以认为是无锁操作。

但是CAS在CPU内部是基于cmpxchg指令去玩的，而且CPU也是多核的。那么在多个核心都去对一个变量进行CAS操作时，×86的CPU中，会添加 **lock前缀指令** ，可能会基于缓存行锁，或者是基于总线锁，只让一个CPU内核执行这个CAS操作。

**有哪些用的地方：**

一般在平时开发的时候，99.999999%用不到，除非你开发一些中间件，框架之类的，可能会涉及到。一般看到的都是在JUC包下的一个并发工具里会涉及到。 比如ReentrantLock，synchronized，ThreadPoolExecutor，CountDownLatch…………

## 28、Java中锁的底层实现？（天润融通）

1、**可以聊CAS，一般到了CPU的cmpxchg指令就到头了。**

2、**可以聊synchronized：**

* 聊对象头里的MarkWord，去聊锁升级，无锁、偏向锁、轻量级锁、重量级锁……

3、**可以聊Lock锁：**

* 聊AQS！

关于synchronized和Lock锁的细节，看2024金三银四突击班里的并发编程2

https://www.mashibing.com/live/2583

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/2746/1724058500034/7181c9bc04e44cbdb6a5f22113d9e631.png)

## 29、为什么HashMap的k-v允许为null，CHM不允许k-v为null？（小米）

HashMap的设计之初，就是为了线程在局部使用的，不存在多线程操作的情况，所以存null与否都不影响当前线程自己的操作。

ConcurrentHashMap的设计就是为了在多线程的情况下去使用。

* **如果允许存储null，那么你在get时，获取到了一个null数据，到底是获取到了还是没获取到呢？**
* 其次这种多线程操作的情况下，null值必然有可能会发生空指针异常的问题。

## 30、hash冲突的话有几种解决方式？（小米）

**链地址法：** HashMap就玩的这种方式，基于key的hashCode和桶位置 - 1做运算，如果出现了相同位置，就形成一个链表挂在一起。在HashMap中，

因为桶位置一般不会超过16个bit位，所以做了一个高低位的^运算，让高位也参与到。（这个算是多次Hash的套路）

**多次Hash：** 这个就是针对一个内容，做多次hash运算。比如先hashCode，然后再crc16之类的，让数值不同。（布隆过滤器就可以采用这个方式）

**公共溢出区：** 将hash表分为基准表和溢出表，但凡出现了hash冲突，就将冲突的数据扔到溢出表里。

**开放定址法：** 有关键字key的哈希地址（i），出现冲突时，以这个地址（i）为基准，产生另一个hash地址（i2），若i2还有冲突，再次以i为基准，再找一个i3，直到找到不冲突的地址，将元素扔进去。

* 线性探测：顺序的往后面找哈希地址~~~比如0有冲突，那就看1，1再有，那就看2，2再有，那就看…………
* 二次（平方）探测：2,4,8…………这么找地址……
* 随机数：随机找…………

## 31、怎么用Runnable实现Callable的功能（菜鸟）

本质就是问的FutureTask。

Runnable和Callable的区别无非就是能否抛异常，是否可以返回一个结果。

可以很直观的看到Runnable和Callale在源码中的区别。

但是Callable如何执行的啊？？

Callable本质需要基于FutureTask去执行，而在FutureTask里，有一个成员变量outcome，任务执行过程的异常或者是返回结果，都会被封装到outcome中，放执行者需要结果时，get方法会返回outcome中存储的内容。

可以在实现Runnable接口时，也声明类似的成员变量，当run方法执行时，整个try-catch住，如果出现异常信息，就将异常封装到这个成员变量中。如果正常执行完，有结果需要返回，就将需要返回的结果扔到成员变量中。

如果你对FutureTask比较了解，你还可以再聊一下给任务追加一个状态，避免任务并发投递时，带来的并发问题。

## 32、ThreadLocal应用场景，key和value分别是什么（蚂蚁）

- **ThreadLocal一般就是再同一个线程中做参数传递的。**

一般场景，比如 **事务的控制** ，需要Service和Mapper使用同一个Connection，那就可以基于ThreadLocal去做参数的传递。

再比如 **链路追踪** ，想记录当前线程的整条日志信息，也可以基于ThreadLocal存储traceID。

再比如在Filter中，从请求头里面获取到了 **Token** ，后期需要在Controller中使用，也可以基于ThreadLocal传递Token信息。

---

本质上，ThreadLocal他不存储数据，真正存储数据的是每个线程Thread对象中的ThreadLocalMap属性。

真正存储数据的容器是Thread类中的ThreadLocalMap。

- **每个线程只有一个 `ThreadLocalMap`**，这个 `Map` 用来存储该线程所有的 `ThreadLocal` 变量。
- 每个线程在第一次使用 ThreadLocal 时，Thread 类会为该线程创建一个 ThreadLocalMap。
- 一旦 ThreadLocalMap 创建后，该线程在后续使用 ThreadLocal 时会直接访问和使用这个 ThreadLocalMap。

**ThreadLocal是作为key的存在，value是你正常存储的数据。**

```java
ThreadLocal<String> local1 = new ThreadLocal<>();
ThreadLocal<Integer> local2 = new ThreadLocal<>();

local1.set("Hello");
local2.set(123);

// 在同一个线程中，local1 和 local2 的数据是独立存储的
System.out.println(local1.get()); // 输出：Hello
System.out.println(local2.get()); // 输出：123
```



使用场景

**1. 数据库连接（Connection）**

- **场景：** 在多线程环境中，每个线程需要独立的数据库连接。

- **原因：** 数据库连接不能在线程之间共享，否则会导致并发问题。

- **示例：**

  ```java
  ThreadLocal<Connection> connectionHolder = new ThreadLocal<>();
  
  public Connection getConnection() {
      if (connectionHolder.get() == null) {
          connectionHolder.set(createNewConnection()); // 初始化数据库连接
      }
      return connectionHolder.get();
  }
  ```

2. **配置或上下文数据**

   **场景：** 在请求的整个生命周期中需要一些配置信息或上下文数据。

   **原因：** 在某些框架或工具中，线程上下文数据可以帮助避免通过方法参数传递。

   **示例：**

   ```java
   ThreadLocal<Map<String, Object>> contextHolder = ThreadLocal.withInitial(HashMap::new);
   
   public void setContext(String key, Object value) {
       contextHolder.get().put(key, value);
   }
   
   public Object getContext(String key) {
       return contextHolder.get().get(key);
   }
   ```



至于ThreadLocal的内存泄漏问题，这里就不展开说了……

看2024金三银四突击班里的**并发编程1**

https://www.mashibing.com/live/2583

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/2746/1724058500034/0c77e5acda2749dfb8baf77999d26115.png)

## 33、子线程如何获取父线程中的属性信息。

main线程下，创建的都是子线程。

**可以采用一些共享变量的方式，来做线程之间的数据传递……**

除此之外，Java中还提供的InheritableThreadLocal类，来实现这个操作。

这个InheritableThreadLocal就是在父线程创建子线程时，将父线程设置到InheritableThreadLocal中的数据直接迁移一份到子线程的InheritableThreadLocal中。

在创建子线程时，会执行Thread的init方法，在init方法中，默认就会做InheritableThreadLocal数据传递的逻辑，只要父线程中的InheritableThreadLocal里面有数据，就会做迁移操作。直接将父线程的inheritableThreadLocals中的数据一个一个的搬到子线程的inheritableThreadLocals里面。

inheritableThreadLocals就是ThreadLocalMap

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/2746/1724058500034/e2bc77f411894e8d86694b43c5cba612.png)

```java
InheritableThreadLocal<String> threadLocal = new InheritableThreadLocal<>();
threadLocal.set("Parent Data");

Thread childThread = new Thread(() -> {
    System.out.println("Child Thread Value: " + threadLocal.get());
});

childThread.start();
System.out.println("Parent Thread Value: " + threadLocal.get());

// sout
Parent Thread Value: Parent Data
Child Thread Value: Parent Data
```

但是有个问题: **静态复制：** 子线程在创建时会复制父线程的数据，**后续父线程修改数据，子线程不会感知**。



## 34、Java中怎么唤醒一个阻塞的线程？（小红书）

唤醒线程的方式：

* interrupt……
* Unsafe.unpark……

首先，线程阻塞的方式，在Java中其实只有一种形式，就是Unsafe类中的park方法去挂起的。

只不过Java中针对这种阻塞的状态，细分了3种：

* BLOCKED：synchronized…………
* WAITING
* TIMED_WAITING

这三个状态，其实对于操作系统来说，没区别，Java中细分的目的是为了让咱们在排查问题时，可以更好的定位。

**Java线程在获取synchronized锁资源失败后，如果该线程执行了interrupt，那这个线程会被唤醒吗？**

答：synchronized加锁的核心逻辑都是在C++内部实现的，如果在基于synchronized挂起后，线程被执行了 **interrupt** ，在C++的代码中，会被唤醒，并且可以执行CAS尝试获取锁资源，但是一般情况下，拿不到就再次被挂起了。而在Java中能看到的效果就是，没有任何效果（没拿到锁）。

其他的类似WAITING和TIMED_WAITING必然也是可以唤醒的，只是根据后续工具的代码逻辑来决定是否能真正的唤醒到自己编写的业务代码中。

比如lock.lock方法，synchronized的阻塞形式，中断后不一定会回到你自己的业务代码中。

但是比如lock.lockInterruptibly，Thread.sleep()，等可以在中断后，抛出interrupt异常能看到效果。

## 35、多个任务，同时达到临界点，主线程执行，怎么实现（去哪）

首先这种方式很多。

* join……

  ```
  t1...
  t2...
  t3...
  主线程：
  t1.join();
  t2.join();
  t3.join();
  // 只要代码到这，代表t1、t2、t3就都完成了~~
  ```

* CountDownLatch……

  ```
  CountDownLatch latch = new CountDownLatch(3);
  t1……(() -> {逻辑代码…………   latch.countDown();})
  t2……(() -> {逻辑代码…………   latch.countDown();})
  t3……(() -> {逻辑代码…………   latch.countDown();})
  主线程：
  latch.await();
  // 只要代码到这，代表t1、t2、t3就都完成了~~
  ```

* FutureTask……

  ```
  FutureTask f1 = t1……
  FutureTask f2 = t2……
  FutureTask f3 = t3……
  主线程：
  f1.get();
  f2.get();
  f3.get();
  // 只要代码到这，代表t1、t2、t3就都完成了~~
  ```

* CompletableFuture

  ```
  CompletableFuture cf = CompletableFuture.allOf(t1,t2,t2);
  cf.join();
  // 只要代码到这，代表t1、t2、t3就都完成了~~
  ```

## 36、让20个线程同一时刻开始执行（昨儿大佬直播间聊到的）

首先，想让20个线程同一时刻开始执行，这个不现实…… 线程是CPU调度的，这个咱们没法控制，所以一般情况下，让线程极可能同一时刻就行……

**直接采用CyclicBarrier工具就可以实现，CyclicBarrier本身就是等待多个线程都到达位置，然后再统一的被唤醒。原理类似于一个计数器，每到位一个线程，就--，并且挂起这个线程。当这个计数器减到0的时候，会将所有的线程唤醒，继续执行后续的逻辑。**

扩展聊：

CyclicBarrier的底层是基于ReentrantLock实现的。你到位的线程会基于await挂起，并且丢到Condition单向链表中。等到计数器到0时，会基于signalAll的方法，将所有到位的线程一个一个的唤醒，每个唤醒的线程还需要到AQS的同步队列中获取锁资源，才能继续往下执行，所以他们是存在先后顺序的。

## 37、CountDownLatch和CyclicBarrier，分别作用于什么业务，哪个可以复用，为什么；（去哪）

CountDownLatch的应用场景：

> CountDownLatch最多的使用场景就是在等待多个线程操作都完成后，再让后续业务继续执行的业务中……
>
> 这么解释没毛病：但是推荐大家，在面试的过程中，这个点最好结合自己的项目去聊……你在哪家公司的哪个项目中的什么功能里，就涉及了………………

CyclicBarrier的应用场景：

> * 比如类似游戏中，玩王者荣耀，LOL等等，需要等待10个客户端都匹配到位，才能开始游戏，这个10个客户端才会开始加载游戏……
> * 比如一个旅游的APP，需要报团，这个团可能有时间限制，同时还有人数的限制，如果撇去时间，等到人数到达了阈值，才会触发后续的一些。
> * 电商拼团，PDD，至少2人成团…………

**哪个可以复用，为什么？**

其实这哥俩都有一个特点，都需要等待多个线程做了什么事情，才能往下继续。

* CountDownLatch是基于AQS中的state做计数，每完成一个任务，countDown方法执行后，会对state - 1，当state为0后，就会唤醒那些基于CountDownLatch执行await的线程。
* CyclicBarrier是自己搞了一个count属性，每当有一个线程到位 **（执行CyclicBarrier的await方法）** 之后，就会对count进行--操作。等到count计数到0后，依然会唤醒，可以优先触发一个任务，然后唤醒所有到位的线程。

CyclicBarrier是可以复用的。 他提供了一个reset的方法，在这个reset方法中，会将所有之前到位，和即将到位的线程全部唤醒结束，同时重置count计数器，清空当前CyclicBarrier，以便下次使用

## 38、线程池的执行过程？（美团）

所谓的执行过程，或者说是执行原理，任务投递后的处理优先级都是一个意思。

任务投递到线程池之后

* 如果当前线程池的线程个数，不满足你设定的核心线程数，那么就会创建核心线程去处理投递过来的任务。
* 如果线程个数等于了你设定的核心线程数，那么任务会尝试投递到工作队列中排队。
  * 工作队列有长度，如果工作队列的长度大于排队的任务数，任务会被正常的投递到工作队列。
* 工作队列中的任务数和现在排队的任务数一致，任务无法投递到工作队列，此时需要创建一个非核心线程来处理刚刚投递过来的任务。
  * 创建非核心线程时，还需要判断一下线程个数是否小于你设定的最大线程数，小于才会正常创建。
* 如果线程个数等于你设定的最大线程数，会执行拒绝策略。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/2746/1724232929056/a590f1b2833140c88ca78b353a9dbe48.png)

## 39、为什么非核心优先执行投递的任务（美团）

首先，线程池的使用是为了提交任务给线程池，让线程池异步处理。

而在提交任务的这个过程中，其实是业务线程在执行的。

**希望业务线程提交任务的过程要尽可能的短一些，让业务线程尽快的执行后续的逻辑。**

- 如果让业务线程创建的非核心线程直接去处理提交过去的任务，速度相对是最快的一种形式。

- 如果让业务线程创建的非核心线程优先去拉取队列中最早投递的任务，然后业务线程再将任务投递到工作队列这种形式，就会让任务投递的过程变慢。

### 核心线程跟非核心线程有什么区别？

答：没区别，核心线程跟非核心线程只有在创建的时候会区分，因为他要根据核心与非核心来决定判断哪个参数。是判断核心线程数，还是最大线程数。 而在干活的时候，他俩都是普通线程。

线程池只关注数量，无论你创建的时候，走的是核心的逻辑，还是非核心的逻辑，我只看数量。即便创建的时候走的是核心线程的逻辑，但是根据线程个人情况，多了一个线程，到达了最大空闲时间，也会干掉这个核心线程。

**这7个参数，哪怕死记硬背，也要熟练的说出来！！！**

```java
    public ThreadPoolExecutor(int corePoolSize,      核心线程数
                              int maximumPoolSize,   最大线程数
                              long keepAliveTime,    最大摸鱼时间……
                              TimeUnit unit,         摸鱼时间单位。
                              BlockingQueue<Runnable> workQueue,     工作队列
                              ThreadFactory threadFactory,           线程工厂
                              RejectedExecutionHandler handler) {    拒绝策略……
```

### 可能会有面试官这么问：核心线程可以被回收吗？

那面试官想问的是这个属性：allowCoreThreadTimeOut

这个属性相当于把你设置的核心线程数的这个属性的效果直接砍掉。

正常指定核心线程数为2个的时候，线程池即便长时间没任务，也要保留2个工作线程

但是如果allowCoreThreadTimeOut设置为true了（默认为false），那么只要工作线程超过了最大空闲时间，我就把你干掉，一个不留！

## 40、（蚂蚁线程池连环问）

#### Java线程池，5核心、10最大、10队列，第6个任务来了是什么状态？

任务扔工作队列里~

#### 如果在第6个任务过来的时候，5个核心线程都已经空闲了呢？

一样扔队列……线程池只关注数量！

#### 第16个任务来了怎么处理？

创建非核心线程去处理这个第16个任务~

#### 第16个任务来了的时候，要是有核心线程空闲了呢？

如果这个空闲的线程，将工作队列中的10个任务，取走了一个，变为了9个，那任务扔队列。

如果空闲的线程还没来得及取走任务，投递时，队列长度依然为10，那还是创建非核心。

#### 队列满了以后执行队列的任务是从队列头 or 队尾取？

一般咱们的阻塞队列都是FIFO的，所以先进先出，从头取。

#### 核心线程和非核心线程执行结束后，谁先执行队列里的任务？

谁谁空闲了，并且去等待任务，谁先去执行队列里的任务。

#### 线程池中的工作线程在执行任务的过程中，如何取消任务的执行？

**研究过FutureTask的源码即可。**

原生的ThreadPoolExecutor在提交普通的Runnable任务时，是无法做到的。

需要提交FutureTask的任务，在任务的处理过程中，**会存储是哪个线程在处理当前的任务**。

这样咱们就可以获取到执行当前任务的线程对象执行他的interrupt方法。如果有中断的出口，那就结束了，但是如果没有中断的出口，那即便你中断了，任务也会执行完毕！

其次也可以在任务还没执行前，通过对任务提供状态的修饰，基于状态来阻止任务执行，



**notify是什么？。看完整版的课时16**











## 41、线程池参数，线程池参数怎么设置（菜鸟）

#### 线程池参数：

> 核心线程数
>
> 最大线程数
>
> 最大空闲时间
>
> 空闲时间单位
>
> 工作队列
>
> 线程工厂
>
> 拒绝策略

#### 线程池参数怎么设置：

面试的时候被问到了你要点到几个信息：

* 你上线的服务器的硬件配置如何（**你的生产环境是4C8G**）
  * CPU内核数
  * 内存大小
* 你线程池处理的任务情况
  * CPU密集
  * IO密集
  * 混合型（既有IO操作，又有CPU操作）

前面的信息点清楚后，直接说你线程池中的 **核心线程数** 设置的是多少，以及你的 **工作队列多长**

* 核心线程数与最大线程数保持一致！ 至于到底是多少，自己提前编一个数值，比如50，比如80，随你。直接聊出来。**数值是你压测出来的**，记住，一定是压测的，你最开始可以给一个预估的数值，但是最终结果是压测的，在你的测试环境压测，测试环境的硬件配置和生产环境一致！ **（有一个前提，如果你任务是混合型的，那50左右没问题，如果是CPU密集的，别太大，基本就是CPU内核数左右）**
* 工作队列用的啥，多长。工作就常用的就俩，要么你用 **ArrayBlockingQueue** ，要么用 **LinkedBlockingQueue** ，这里我推荐大家统一 **LinkedBlockingQueue** 。因为你们的领导说了， **LinkedBlockingQueue** 底层是链表，工作队列本身就是增删比较频繁的情况，所以直接让我们用的 **LinkedBlockingQueue** ，效率相对更好。
  * 至于长度：
    * 这里你要说清楚你们这个任务触发的并发情况，如果任务体量比较大，会造成内存占用率过大。
    * 任务的延迟时间允许的范围，如果队列太长，任务被处理时，最大的延迟时间能否接收。
  * 队列长度要直接说是多少，一般情况就是和核心线程的2倍左右，一般情况没问题。  **100长度，150长度，200长度~~**

## 42、一般就是你针对大致业务和Tomcat或者一些中间件的线程池如何配置的，然后在压测的时候，你都查看什么指标？（前几天一学员的）

> 一般聊压测要查看的指标时，方向贼多。最核心的几个：
>
> * **CPU占用率：**
>   * 其中IO密集的任务，很难让CPU的占用率提升太大，所以IO密集，不需要提太多CPU占用率问题
>   * 其次在混合型或者CPU密集的任务中，需要时刻关注CPU占用率的情况，一般只要不超过70%基本没啥问题，最好控制在50~60左右。
> * **内存资源：**
>   * 内存资源自然是线程本身也会占用，一般占用1M。而且任务的处理过程也需要占用额外的内存资源，并且在队列中排队的任务也是一个对象，他也占用内存资源。不能让内存资源占用过多，比如在峰值的情况下，50~60%左右就可以了。
> * 磁盘资源：这个一般不用太考虑，毕竟现在都是固态，速度是ok的。
> * 还需要查看任务的处理情况的指标：
>   * **吞吐量：** 单位时间内，处理任务的个数。（越大越好）   **500个/s**
>   * **RT响应时间：** 每个任务的平均处理速度。（越小越好）  **200ms**
> * 还需要查看 **GC的情况** ，如果任务体量比较大，如果新生代的内存不够充裕，可能会导致对象直接甩到老年代，或者新生态频繁的GC，就可能会导致FULL GC频繁的情况。**（比如说，出现了这个情况，可以将新生态的比例调大）**
> * **其他资源：** 比如你任务需要访问数据库（MySQL），必然需要Connection，访问其他服务。
> * 网络情况： 在访问三方服务时，他的延迟情况是如何的。网络延迟是否会受到影响。
> * 还有在这种长时间的压测环境下，系统能否正常的长时间稳定运行。
>
> 线程池参数配置过程：
>
> 1、优先根据配置自己确认要一个预估的数值，然后开始压测，查看指标情况。
>
> 2、逐渐的调整并发的数值，以及线程池的参数，去查看这些性能指标。
>
> 3、如果在逐渐的调整数值后，依然无法得到你性能的要求。根据前面的指标，查看瓶颈在哪 ，做优化。
>
> 4、重复2~3操作，直到，达到你的性能要求…………、
>
> 拒绝策略，在压测的时候就要规避好。因为执行了拒绝策略，必然要做监控预警通知咱们，最好的情况记录日志信息，及时的解决。

## 43、CopyOnWrite 怎么保证线程安全，为什么这么做？（协程）

**写写互斥，写读、读写不互斥，读读也不互斥。**

CopyOnWrite系列的并发集合，是基于再写入操作前，需要先获取ReentrantLock，毕竟写写操作是互斥的，然后先将本地的数据复制一份，在复制的内容中去完成写操作，在写完之后，将复制的内容覆盖掉本地的原数据。

* 前面的ReentrantLock，可以让写写操作直接互斥，达到线程安全的目的。
* 为什么还要改个副本，在副本里写的，这样内存占用率不就是double了么~~
  * 因为还有读操作，CopyOnWrite为了提升读的性能，没有让读写之间出现互斥的操作。读和写是可以并行执行的。在有线程进行读操作时，直接读取本地的数据，写入的线程就正常的先去写到副本中。

在使用ArrayList这种线程不安全的集合时，如果需要声明到成员变量，多个线程都去访问的时候，并且读操作居多时，就应当上CopyOnWrite的系列。

## 44、ConcurrentHashMap在红黑树的读写并发会发生什么？（我问的）

扫盲的内容：

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/fyfile/2746/1724311354012/c9ba3e6dbea742d487b2c2081a9a6017.png)

红黑树为了保证平衡，在写入数据时，可能会做旋转、变色的操作。

- 如果红黑树上的读写可以**并行执行**，那就造成读线程在遍历红黑树找数据时，因为写操作的旋转，从而没找到。但是数据其实是存在的，可能会有**影响**到你的业务。

- 转换为红黑树后，链表依然存在在（变成双向链表）

- 如果真的发生了写线程正在写数据到红黑树，此时再来了一个读线程，并不会让读线程阻塞等待，而是直接让读线程去双向链表（单向链表）中查询数据，虽然速度慢了一内内，但是查询会进行下去…… 

  

**读线程怎么知道是否有写线程正在红黑树里写数据呢？**

基于下面这个int类型的数值，作为一个锁标记

`int lockState;`

```java
00000000
在二进制中。
最低位是1 （00000001），代表有写线程在里面写数据。
第二低位是1 （00000010），代表有写线程排队等待读线程完毕，再去写。这时候过来的线程要是再想读，就直接去双向链表读
第三低位往上不为0，就代表有读线程正在红黑树里读取数据。
```

如果写线程发现有读线程正在红黑树里找数据，那写线程需要等一会，基于park挂起~~~

## 45、有在项目中实际使用过ConcurrentHashMap吗？哪些场景会用到？（京东健康）

ConcurrentHashMap本质就是做缓存的！将一些热点数据甩到ConcurrentHashMap里，他的速度比Redis快。毕竟你找Redis要数据，还得走一个网络IO的成本，ConcurrentHashMap就是JVM内部的数据。

比如数据已经从MySQL同步到Redis里了，但是Redis的性能不达标，或者Redis节点本身压力就比较大。那咱们就可以将缓存前置到JVM缓存中，利用ConcurrentHashMap去存储。

但是这种方式存储，如果JVM节点是集群部署，那就必然会存在不一致的问题。

* 强行走强一致，让你的缓存的存在没啥意义。。。（不这么玩）
* 通过一些中间件，MQ，Zookeeper等都可以做大监听通知或者广播的效果，这种同步可能存在延迟，达到最终一致性。
* 将一些访问量特别频繁的数据，扔到JVM内存，就生存1s甚至更少，这样可以较少对Redis的压力……同时在短时间内，也能提升性能……

类似Nacos，Eureka这种注册中心，就用到了ConcurrentHashMap，将注册中心里的注册列表的所有服务信息拉取到本地的ConcurrentHashMap中。

Spring的三级缓存用的啥？？不也是ConcurrentHashMap么~~BeanDefinition

## 46、工作中的死锁怎么处理（京东健康）

问得少

面试的时候，记得聊到死锁，必聊四个点，就背！！！

**互斥条件，请求保持，不可剥夺，环路**………………

**互斥条件（一般玩的就是互斥锁！）**
每个资源只能被一个线程使用，不能被同时占用。这意味着如果有两个进程试图同时使用同一个资源，就会发生冲突。例如，如果两个进程同时尝试修改同一个文件的内容，就会导致数据混乱。互斥条件是死锁的必要条件之一，因为如果资源可以同时被多个进程使用，就不会出现死锁的情况。

**请求与保持条件（一个线程在持有一个锁资源时，需要再拿另一个资源，而且之前的锁资源不释放）**
一个线程需要获取新的资源才能继续执行，但已经占有的资源不能被释放。这意味着如果一个进程已经占有了某些资源，那么它还需要获取更多的资源才能继续执行。例如，如果一个进程已经占有了两个资源A和B，但它还需要一个资源C才能继续执行，而资源C已经被另一个进程占用，那么这个进程就会陷入死锁。

**不剥夺条件（锁资源只能自己释放，别人不能释放！）**
已经分配给进程的资源不能被强制剥夺。这意味着如果一个进程已经占有了某些资源，那么除非它自己释放，否则其他进程或系统不能强制剥夺这些资源。例如，如果一个进程已经占有了两个资源A和B，但系统强行剥夺了其中一个资源A，那么这个进程就会陷入死锁。

**环路等待条件（线程1持有A资源，同时要B资源，线程2只有B资源，同时想要A资源）**
多个进程形成一种头尾相接的环路，每个进程都占用了一些资源，但又都需要得到下一个未占用的资源。这意味着如果多个进程形成了一个环路，每个进程都等待下一个进程释放资源，那么这个环路上的所有进程都会陷入死锁。例如，有三个进程A、B、C，A需要资源1和资源2，B需要资源2和资源3，C需要资源3和资源1，那么A、B、C就会形成一个环路等待条件，导致所有进程陷入死锁。

**定位方式：**

> jstack：
>
> ```
> jps，查看具体的进行的pid
> jstack pid ,直接就会打印出死锁信息
> ```
>
> arthas：
>
> ```
> 需要你自己优先下载一个jar包。
> yum -y install wget
> wget https://alibaba.github.io/arthas/arthas-boot.jar
> 在有Java环境的情况下，直接
> java -jar arthas-boot.jar
> 跑起来后，会让你选择监控的JVM进程谁，写编号就成。
> 继续的命令，就help，或者看看官方文档
> thread -b 就能直接看到对应阻塞线程名
> ```

**解决方式：**

* 规避业务中出现环路等待锁的情况，这种业务的设计就存在问题。
* 不要走lock这种死等的方式，可以采用tryLock等待一小会，拿不到就拉到。

## 47、手撕多线程，三个线程轮流打印123/ijk，打印10次。（阿里一面手撕）

可以采用的方式很多，比如基于synchronized的wait和notify通知线程实现顺序打印。

甚至还能用ReentrantLock的公平锁去实现，但是这个不太稳定……

咱们花活，直接上Semaphore，我就写一种了~~~

```java
public static void main(String[] args) {
    // 修改：s1 初始许可为 1
    Semaphore s1 = new Semaphore(1);
    Semaphore s2 = new Semaphore(0);
    Semaphore s3 = new Semaphore(0);

    Thread T1 = new Thread(() -> {
        for (int i = 0; i < 10; i++) {
            try {
                s1.acquire();  // 初始 s1=1，第一次可获取
                System.out.println("t1");
                s2.release();  // 释放 s2 给 T2
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
        }
    });

    Thread T2 = new Thread(() -> {
        for (int i = 0; i < 10; i++) {
            try {
                s2.acquire();  // 等待 T1 释放 s2
                System.out.println("t2");
                s3.release();  // 释放 s3 给 T3
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
        }
    });

    Thread T3 = new Thread(() -> {
        for (int i = 0; i < 10; i++) {
            try {
                s3.acquire();  // 等待 T2 释放 s3
                System.out.println("t3");
                s1.release();  // 释放 s1 给 T1，继续循环
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
        }
    });

    T1.start(); T2.start(); T3.start();
}
```

**信号量的初始值 0 意味着什么？**

- 初始状态无可用许可：new Semaphore(0) 表示初始时许可数量为 0，`所有调用 acquire() 的线程会立即阻塞`（除非其他线程先调用release() 释放许可）。
- 许可的本质：信号量的许可是一个计数器，不强制与线程绑定。即使初始为 0，后续可以通过 release()动态增加许可数量。



**核心逻辑：为什么必须有一个信号量初始为 1？**

可以将信号量想象成 **钥匙**：

- **初始值为 0**：意味着没有钥匙，所有线程会卡在第一个 `acquire()`，无法继续。
- **初始值为 1**：相当于给第一个线程（例如 T1）一把钥匙，让它能启动执行，完成任务后把钥匙传递给下一个线程（例如 T2），依此类推。

------

**钥匙传递的流程（以你的代码为例）**

假设初始设置：

- `s1 = 1`（T1 初始有钥匙）
- `s2 = 0`（T2 初始无钥匙）
- `s3 = 0`（T3 初始无钥匙）

**执行步骤**：

1. **T1 启动**：
   - `s1.acquire()`：获取到钥匙（`s1` 从 1 → 0）。
   - 打印 `t1`。
   - `s2.release()`：给 T2 一把钥匙（`s2` 从 0 → 1）。
2. **T2 启动**：
   - `s2.acquire()`：获取到钥匙（`s2` 从 1 → 0）。
   - 打印 `t2`。
   - `s3.release()`：给 T3 一把钥匙（`s3` 从 0 → 1）。
3. **T3 启动**：
   - `s3.acquire()`：获取到钥匙（`s3` 从 1 → 0）。
   - 打印 `t3`。
   - `s1.release()`：给 T1 一把钥匙（`s1` 从 0 → 1）。
4. **循环重复**：
   - T1 再次获取 `s1` 的钥匙，继续执行。

------

### **为什么初始值全为 0 会失败？**

- **所有线程被阻塞**：每个线程的第一个操作都是 `acquire()`，但初始没有钥匙，所有线程永久等待。
- **没有线程能释放钥匙**：无法形成“传递链”，导致死锁。







